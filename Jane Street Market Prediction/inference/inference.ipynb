{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043748,
     "end_time": "2021-02-05T05:30:02.012671",
     "exception": false,
     "start_time": "2021-02-05T05:30:01.968923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Jane Street: Neural Network Starter\n",
    "\n",
    "I try implementing a simple Tensorflow Keras neural network here. Train in Version 17.\n",
    "\n",
    "**Caution:** The GroupCV method applied in this notebook may cause time leakage problem. Please use [Purged Time-Series CV][1] instead.\n",
    "\n",
    "[1]: https://www.kaggle.com/marketneutral/purged-time-series-cv-xgboost-optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:02.098503Z",
     "iopub.status.busy": "2021-02-05T05:30:02.097688Z",
     "iopub.status.idle": "2021-02-05T05:30:02.101946Z",
     "shell.execute_reply": "2021-02-05T05:30:02.102601Z"
    },
    "papermill": {
     "duration": 0.050168,
     "end_time": "2021-02-05T05:30:02.102829",
     "exception": false,
     "start_time": "2021-02-05T05:30:02.052661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:02.199214Z",
     "iopub.status.busy": "2021-02-05T05:30:02.198432Z",
     "iopub.status.idle": "2021-02-05T05:30:02.211579Z",
     "shell.execute_reply": "2021-02-05T05:30:02.212185Z"
    },
    "papermill": {
     "duration": 0.069133,
     "end_time": "2021-02-05T05:30:02.212365",
     "exception": false,
     "start_time": "2021-02-05T05:30:02.143232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LiteModel:\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, model_path):\n",
    "        return LiteModel(tf.lite.Interpreter(model_path=model_path))\n",
    "    \n",
    "    @classmethod\n",
    "    def from_keras_model(cls, kmodel):\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(kmodel)\n",
    "        tflite_model = converter.convert()\n",
    "        return LiteModel(tf.lite.Interpreter(model_content=tflite_model))\n",
    "    \n",
    "    def __init__(self, interpreter):\n",
    "        self.interpreter = interpreter\n",
    "        self.interpreter.allocate_tensors()\n",
    "        input_det = self.interpreter.get_input_details()[0]\n",
    "        output_det = self.interpreter.get_output_details()[0]\n",
    "        self.input_index = input_det[\"index\"]\n",
    "        self.output_index = output_det[\"index\"]\n",
    "        self.input_shape = input_det[\"shape\"]\n",
    "        self.output_shape = output_det[\"shape\"]\n",
    "        self.input_dtype = input_det[\"dtype\"]\n",
    "        self.output_dtype = output_det[\"dtype\"]\n",
    "        \n",
    "    def predict(self, inp):\n",
    "        inp = inp.astype(self.input_dtype)\n",
    "        count = inp.shape[0]\n",
    "        out = np.zeros((count, self.output_shape[1]), dtype=self.output_dtype)\n",
    "        for i in range(count):\n",
    "            self.interpreter.set_tensor(self.input_index, inp[i:i+1])\n",
    "            self.interpreter.invoke()\n",
    "            out[i] = self.interpreter.get_tensor(self.output_index)[0]\n",
    "        return out\n",
    "    \n",
    "    def predict_single(self, inp):\n",
    "        \"\"\" Like predict(), but only for a single record. The input data can be a Python list. \"\"\"\n",
    "        inp = np.array([inp], dtype=self.input_dtype)\n",
    "        self.interpreter.set_tensor(self.input_index, inp)\n",
    "        self.interpreter.invoke()\n",
    "        out = self.interpreter.get_tensor(self.output_index)\n",
    "        return out[0]\n",
    "    \n",
    "    def predict_single2(self, inp):\n",
    "        \"\"\" Like predict(), but only for a single record. The input data can be a Python list. \"\"\"\n",
    "        self.interpreter.set_tensor(self.input_index, inp)\n",
    "        self.interpreter.invoke()\n",
    "        out = self.interpreter.get_tensor(self.output_index)\n",
    "        return out\n",
    "    \n",
    "    def predict_lstm(self, inp):\n",
    "        self.interpreter.set_tensor(self.input_index, inp)\n",
    "        self.interpreter.invoke()\n",
    "        result = self.interpreter.get_tensor(self.output_index)\n",
    "        return result[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:02.310426Z",
     "iopub.status.busy": "2021-02-05T05:30:02.309176Z",
     "iopub.status.idle": "2021-02-05T05:30:13.019401Z",
     "shell.execute_reply": "2021-02-05T05:30:13.018753Z"
    },
    "papermill": {
     "duration": 10.766686,
     "end_time": "2021-02-05T05:30:13.019566",
     "exception": false,
     "start_time": "2021-02-05T05:30:02.252880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#if TRAINING:\n",
    "#    import cudf\n",
    "#    import cupy as cp\n",
    "\n",
    "import os, gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from joblib import dump, load\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:13.115388Z",
     "iopub.status.busy": "2021-02-05T05:30:13.112212Z",
     "iopub.status.idle": "2021-02-05T05:30:13.120036Z",
     "shell.execute_reply": "2021-02-05T05:30:13.119246Z"
    },
    "papermill": {
     "duration": 0.059323,
     "end_time": "2021-02-05T05:30:13.120193",
     "exception": false,
     "start_time": "2021-02-05T05:30:13.060870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET = 'action'\n",
    "FEATS = ['feature_{}'.format(int(i)) for i in range(130)]\n",
    "SEED = 42\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:13.212419Z",
     "iopub.status.busy": "2021-02-05T05:30:13.211321Z",
     "iopub.status.idle": "2021-02-05T05:30:13.215199Z",
     "shell.execute_reply": "2021-02-05T05:30:13.214496Z"
    },
    "papermill": {
     "duration": 0.053311,
     "end_time": "2021-02-05T05:30:13.215328",
     "exception": false,
     "start_time": "2021-02-05T05:30:13.162017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_autoencoder(input_dim,output_dim,noise=0.1):\n",
    "    i = Input(130)\n",
    "    mask = Input(130)\n",
    "    encoded = BatchNormalization()(i)\n",
    "    encoded = GaussianNoise(noise)(encoded)\n",
    "    \n",
    "    encoded = Dense(96, activation = 'elu')(encoded)\n",
    "    encoded = Dense(64,activation='linear')(encoded)\n",
    "    encoder = Model(inputs=i,outputs=encoded)\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:13.303968Z",
     "iopub.status.busy": "2021-02-05T05:30:13.302889Z",
     "iopub.status.idle": "2021-02-05T05:30:13.563236Z",
     "shell.execute_reply": "2021-02-05T05:30:13.562424Z"
    },
    "papermill": {
     "duration": 0.307357,
     "end_time": "2021-02-05T05:30:13.563390",
     "exception": false,
     "start_time": "2021-02-05T05:30:13.256033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = create_autoencoder(130, 5, noise=0.1)\n",
    "encoder.load_weights('../input/js-cv-split2/encoder.hdf5')\n",
    "encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:13.662056Z",
     "iopub.status.busy": "2021-02-05T05:30:13.661166Z",
     "iopub.status.idle": "2021-02-05T05:30:13.666016Z",
     "shell.execute_reply": "2021-02-05T05:30:13.666619Z"
    },
    "papermill": {
     "duration": 0.061024,
     "end_time": "2021-02-05T05:30:13.666791",
     "exception": false,
     "start_time": "2021-02-05T05:30:13.605767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model1(input_dim,output_dim):\n",
    "    inputs = Input(input_dim)\n",
    "    \n",
    "    #x = encoder(inputs)\n",
    "    #x = Concatenate()([x,inputs]) #use both raw and encoded features\n",
    "    x = BatchNormalization()(inputs)\n",
    "    \n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Lambda(tf.keras.activations.swish)(x)\n",
    "    x = Dropout(0)(x)    \n",
    "    \n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Lambda(tf.keras.activations.swish)(x)\n",
    "    x = Dropout(0)(x)\n",
    "    \n",
    "    x = Dense(300)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Lambda(tf.keras.activations.swish)(x)\n",
    "    x = Dropout(0)(x)\n",
    "    \n",
    "    \n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Lambda(tf.keras.activations.swish)(x)\n",
    "    x = Dropout(0)(x)\n",
    "    \n",
    "    x = Dense(output_dim,activation='sigmoid', name = 'label_output')(x)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:13.766876Z",
     "iopub.status.busy": "2021-02-05T05:30:13.765642Z",
     "iopub.status.idle": "2021-02-05T05:30:13.770509Z",
     "shell.execute_reply": "2021-02-05T05:30:13.771169Z"
    },
    "papermill": {
     "duration": 0.062853,
     "end_time": "2021-02-05T05:30:13.771350",
     "exception": false,
     "start_time": "2021-02-05T05:30:13.708497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_model2(input_dim,output_dim):\n",
    "    inputs = Input(input_dim)\n",
    "    \n",
    "    #x = encoder(inputs)\n",
    "    #x = Concatenate()([x,inputs]) #use both raw and encoded features\n",
    "    x = BatchNormalization()(inputs)\n",
    "\n",
    "    x = Dense(438)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Lambda(tf.keras.activations.swish)(x)\n",
    "    x = Dropout(0)(x)\n",
    "\n",
    "    x = Dense(420)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Lambda(tf.keras.activations.swish)(x)\n",
    "    x = Dropout(0)(x)\n",
    "\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Lambda(tf.keras.activations.swish)(x)\n",
    "    x = Dropout(0)(x)\n",
    "    \n",
    "\n",
    "    x = Dense(output_dim,activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs,outputs=x)\n",
    "    model.compile(optimizer=Adam(0.0072342),loss=BinaryCrossentropy(label_smoothing=0.090004),metrics=[tf.keras.metrics.AUC(name = 'auc')])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:13.870454Z",
     "iopub.status.busy": "2021-02-05T05:30:13.869240Z",
     "iopub.status.idle": "2021-02-05T05:30:28.406777Z",
     "shell.execute_reply": "2021-02-05T05:30:28.404776Z"
    },
    "papermill": {
     "duration": 14.594971,
     "end_time": "2021-02-05T05:30:28.406938",
     "exception": false,
     "start_time": "2021-02-05T05:30:13.811967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "model = create_model2(130 + 64 + 88, 5)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/model2_3.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)\n",
    "    \n",
    "model = create_model1(130 + 64 + 88, 5)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/model_4.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)\n",
    "        \n",
    "model = create_model1(130 + 64 + 88, 5)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/model_5.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:28.517977Z",
     "iopub.status.busy": "2021-02-05T05:30:28.512598Z",
     "iopub.status.idle": "2021-02-05T05:30:28.737291Z",
     "shell.execute_reply": "2021-02-05T05:30:28.736492Z"
    },
    "papermill": {
     "duration": 0.281451,
     "end_time": "2021-02-05T05:30:28.737427",
     "exception": false,
     "start_time": "2021-02-05T05:30:28.455976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Input, Multiply, Add, Concatenate\n",
    "from tensorflow.keras.activations import sigmoid, relu\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.activations import softmax\n",
    "\n",
    "\n",
    "def build_tabnet_model(input_dim, transform_dim, N_a, N_d, num_decision_step, gamma, output_dim, B_v, m_d, Lambda, multiplier):\n",
    "    # Initialization\n",
    "    inputs = Input(input_dim)\n",
    "    #x2 = encoder(x1)\n",
    "    #x = Concatenate()([x1, x2])\n",
    "    #P = tf.ones([tf.shape(x)[0], tf.shape(x)[1]]) #\n",
    "    #d_out = tf.zeros([tf.shape(x)[0], N_d])\n",
    "    #entropy = 0\n",
    "    # pre-encoding\n",
    "    \n",
    "    x = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(inputs)\n",
    "    feat_trans1 = Dense(transform_dim * 2, use_bias= False)(x)\n",
    "    feat_trans1 = Dropout(0)(feat_trans1)\n",
    "    feat_trans1 = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(feat_trans1)\n",
    "    feat_trans1 = Multiply()([feat_trans1[:,:transform_dim], sigmoid(feat_trans1[:,transform_dim:])])\n",
    "    \n",
    "    feat_trans2 = Dense(transform_dim * 2, use_bias = False)(feat_trans1)\n",
    "    feat_trans2 = Dropout(0)(feat_trans2)\n",
    "    feat_trans2 = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(feat_trans2)\n",
    "    feat_trans2 = Multiply()([feat_trans2[:,:transform_dim], sigmoid(feat_trans2[:,transform_dim:])])\n",
    "    feat_trans2 = Add()([feat_trans2, feat_trans1])\n",
    "    feat_trans2 *= tf.math.sqrt(0.5)\n",
    "    \n",
    "    feat_trans3 = Dense(transform_dim * 2, use_bias = False)(feat_trans2)\n",
    "    feat_trans3 = Dropout(0)(feat_trans3)\n",
    "    feat_trans3 = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(feat_trans3)\n",
    "    feat_trans3 = Multiply()([feat_trans3[:,:transform_dim], sigmoid(feat_trans3[:,transform_dim:])])\n",
    "    feat_trans3 = Add()([feat_trans3, feat_trans2])\n",
    "    feat_trans3 *= tf.math.sqrt(0.5)\n",
    "    \n",
    "    feat_trans4 = Dense(transform_dim * 2, use_bias = False)(feat_trans3)\n",
    "    feat_trans4 = Dropout(0)(feat_trans4)\n",
    "    feat_trans4 = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(feat_trans4)\n",
    "    feat_trans4 = Multiply()([feat_trans4[:,:transform_dim], sigmoid(feat_trans4[:,transform_dim:])])\n",
    "    feat_trans4 = Add()([feat_trans4, feat_trans3])\n",
    "    feat_trans4 *= tf.math.sqrt(0.5)\n",
    "    \n",
    "    for step in range(num_decision_step):\n",
    "        #Attentive transform\n",
    "        \n",
    "        mask_value = Dense(input_dim, use_bias= False)(feat_trans4[:,-N_a:])\n",
    "        mask_value = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(mask_value)\n",
    "        if step == 0:\n",
    "            mask_value = softmax(multiplier * mask_value)\n",
    "            P = (gamma - mask_value)\n",
    "        else:\n",
    "            mask_value *= P\n",
    "            mask_value = softmax(multiplier * mask_value)\n",
    "            P *= (gamma - mask_value)\n",
    "\n",
    "        masked_feature = Multiply()([mask_value, inputs])\n",
    "        \n",
    "        \n",
    "        # Entropy is used to penalize the amount of sparsity in feature\n",
    "        # selection.\n",
    "        #entropy += tf.reduce_mean(tf.reduce_sum(-mask_value * tf.math.log(mask_value + 0.01), axis=1)) / (num_decision_step)\n",
    "        \n",
    "        \n",
    "        # feature_transform\n",
    "        feat_trans1 = Dense(transform_dim * 2, use_bias= False)(masked_feature)\n",
    "        feat_trans1 = Dropout(0)(feat_trans1)\n",
    "        feat_trans1 = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(feat_trans1)\n",
    "        feat_trans1 = Multiply()([feat_trans1[:,:transform_dim], sigmoid(feat_trans1[:,transform_dim:])])\n",
    "    \n",
    "        feat_trans2 = Dense(transform_dim * 2, use_bias = False)(feat_trans1)\n",
    "        feat_trans2 = Dropout(0)(feat_trans2)\n",
    "        feat_trans2 = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(feat_trans2)\n",
    "        feat_trans2 = Multiply()([feat_trans2[:,:transform_dim], sigmoid(feat_trans2[:,transform_dim:])])\n",
    "        feat_trans2 = Add()([feat_trans2, feat_trans1])\n",
    "        feat_trans2 *= tf.math.sqrt(0.5)\n",
    "    \n",
    "        feat_trans3 = Dense(transform_dim * 2, use_bias = False)(feat_trans2)\n",
    "        feat_trans3 = Dropout(0)(feat_trans3)\n",
    "        feat_trans3 = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(feat_trans3)\n",
    "        feat_trans3 = Multiply()([feat_trans3[:,:transform_dim], sigmoid(feat_trans3[:,transform_dim:])])\n",
    "        feat_trans3 = Add()([feat_trans3, feat_trans2])\n",
    "        feat_trans3 *= tf.math.sqrt(0.5)\n",
    "        \n",
    "        feat_trans4 = Dense(transform_dim * 2, use_bias = False)(feat_trans3)\n",
    "        feat_trans4 = Dropout(0)(feat_trans4)\n",
    "        feat_trans4 = BatchNormalization(virtual_batch_size=B_v, momentum = m_d)(feat_trans4)\n",
    "        feat_trans4 = Multiply()([feat_trans4[:,:transform_dim], sigmoid(feat_trans4[:,transform_dim:])])\n",
    "        feat_trans4 = Add()([feat_trans4, feat_trans3])\n",
    "        feat_trans4 *= tf.math.sqrt(0.5)\n",
    "        \n",
    "        # ouput\n",
    "        if step == 0:\n",
    "            d_out = relu(feat_trans4[:,:N_d])\n",
    "        else:\n",
    "            d_out += relu(feat_trans4[:,:N_d])\n",
    "        \n",
    "    y1 = Dense(output_dim, activation = 'sigmoid', name = 'label_out')(d_out)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = y1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:28.834869Z",
     "iopub.status.busy": "2021-02-05T05:30:28.829103Z",
     "iopub.status.idle": "2021-02-05T05:30:52.133852Z",
     "shell.execute_reply": "2021-02-05T05:30:52.131456Z"
    },
    "papermill": {
     "duration": 23.355725,
     "end_time": "2021-02-05T05:30:52.134022",
     "exception": false,
     "start_time": "2021-02-05T05:30:28.778297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_tabnet_model(130 + 64 + 88, 32, 16, 16, 3, 1.2, 5, None, 0.8, 0, 6)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/tabnet_model_42_3_multiplier_6_version2.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)\n",
    "\n",
    "model = build_tabnet_model(130 + 64 + 88, 32, 16, 16, 3, 1.2, 5, None, 0.8, 0, 4)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/tabnet_model_42_4_multiplier_4_version4.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)\n",
    "\n",
    "model = build_tabnet_model(130 + 64 + 88, 32, 16, 16, 3, 1.2, 5, None, 0.8, 0, 4)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/tabnet_model_42_5_multiplier_4_version8.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:52.227827Z",
     "iopub.status.busy": "2021-02-05T05:30:52.226731Z",
     "iopub.status.idle": "2021-02-05T05:30:52.232892Z",
     "shell.execute_reply": "2021-02-05T05:30:52.232030Z"
    },
    "papermill": {
     "duration": 0.057279,
     "end_time": "2021-02-05T05:30:52.233031",
     "exception": false,
     "start_time": "2021-02-05T05:30:52.175752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, AveragePooling1D, MaxPooling1D, Flatten, Multiply\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Input, Multiply, Add, Concatenate, Softmax\n",
    "from tensorflow.keras.activations import sigmoid, relu\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.activations import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:52.326279Z",
     "iopub.status.busy": "2021-02-05T05:30:52.325260Z",
     "iopub.status.idle": "2021-02-05T05:30:52.330874Z",
     "shell.execute_reply": "2021-02-05T05:30:52.330023Z"
    },
    "papermill": {
     "duration": 0.056644,
     "end_time": "2021-02-05T05:30:52.331004",
     "exception": false,
     "start_time": "2021-02-05T05:30:52.274360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "      q: query shape == (..., seq_len_q, depth)\n",
    "      k: key shape == (..., seq_len_k, depth)\n",
    "      v: value shape == (..., seq_len_v, depth_v)\n",
    "      mask: Float tensor with shape broadcastable \n",
    "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "      output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = Softmax()(scaled_attention_logits)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:52.434781Z",
     "iopub.status.busy": "2021-02-05T05:30:52.429605Z",
     "iopub.status.idle": "2021-02-05T05:30:52.443333Z",
     "shell.execute_reply": "2021-02-05T05:30:52.442707Z"
    },
    "papermill": {
     "duration": 0.071473,
     "end_time": "2021-02-05T05:30:52.443492",
     "exception": false,
     "start_time": "2021-02-05T05:30:52.372019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transformer_model(input_dim1, window_size, d_model, rate, num_layers, dff, num_heads, output_dim):\n",
    "    inputs = Input(input_dim1)\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    #mask = create_look_ahead_mask(seq)\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(d_model * window_size, use_bias = False)(x)\n",
    "    x = tf.reshape(x, (batch_size, window_size, d_model))\n",
    "    \n",
    "    #x *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    #x += positional_encoding(seq, d_model)\n",
    "    #x = Dropout(rate)(x)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        \n",
    "        #multihead_attention\n",
    "        q = Dense(d_model)(x)\n",
    "        k = Dense(d_model)(x)\n",
    "        v = Dense(d_model)(x)\n",
    "        \n",
    "        q = tf.reshape(q, (batch_size, -1, num_heads, d_model//num_heads))\n",
    "        q = tf.transpose(q, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        k = tf.reshape(k, (batch_size, -1, num_heads, d_model//num_heads))\n",
    "        k = tf.transpose(k, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        v = tf.reshape(v, (batch_size, -1, num_heads, d_model//num_heads))\n",
    "        v = tf.transpose(v, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        attn_out, _ = scaled_dot_product_attention(q, k, v, None)\n",
    "        attn_out = tf.transpose(attn_out, perm=[0, 2, 1, 3])  \n",
    "        attn_out = tf.reshape(x, (batch_size, -1, d_model))  \n",
    "        attn_out = Dense(d_model)(attn_out)  \n",
    "        attn_out = Dropout(rate)(attn_out)\n",
    "        attn_out = BatchNormalization()(attn_out + x)\n",
    "        \n",
    "        fnn_out = Dense(dff, activation= 'relu')(attn_out)  # (batch_size, seq_len, dff)\n",
    "        fnn_out = Dense(d_model)(fnn_out)\n",
    "        fnn_out = Dropout(rate)(fnn_out)\n",
    "        x = BatchNormalization()(fnn_out + attn_out)\n",
    "        if i <= 1:\n",
    "            x = AveragePooling1D(2)(x)\n",
    "        else:\n",
    "            x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Dense(64)(x)\n",
    "    x = Flatten()(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Dense(output_dim, activation = 'sigmoid', name = 'label_out')(x)\n",
    "    model = Model(inputs = inputs, outputs = x)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:52.543704Z",
     "iopub.status.busy": "2021-02-05T05:30:52.542914Z",
     "iopub.status.idle": "2021-02-05T05:30:52.555422Z",
     "shell.execute_reply": "2021-02-05T05:30:52.554590Z"
    },
    "papermill": {
     "duration": 0.070582,
     "end_time": "2021-02-05T05:30:52.555563",
     "exception": false,
     "start_time": "2021-02-05T05:30:52.484981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transformer_model2(input_dim1, window_size, d_model, rate, num_layers, dff, num_heads, output_dim):\n",
    "    inputs = Input(input_dim1)\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    #mask = create_look_ahead_mask(seq)\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(d_model * window_size, use_bias = False)(x)\n",
    "    x = tf.reshape(x, (batch_size, window_size, d_model))\n",
    "    \n",
    "    #x *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    #x += positional_encoding(seq, d_model)\n",
    "    #x = Dropout(rate)(x)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        \n",
    "        #multihead_attention\n",
    "        q = Dense(d_model)(x)\n",
    "        k = Dense(d_model)(x)\n",
    "        v = Dense(d_model)(x)\n",
    "        \n",
    "        q = tf.reshape(q, (batch_size, -1, num_heads, d_model//num_heads))\n",
    "        q = tf.transpose(q, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        k = tf.reshape(k, (batch_size, -1, num_heads, d_model//num_heads))\n",
    "        k = tf.transpose(k, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        v = tf.reshape(v, (batch_size, -1, num_heads, d_model//num_heads))\n",
    "        v = tf.transpose(v, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        attn_out, _ = scaled_dot_product_attention(q, k, v, None)\n",
    "        attn_out = tf.transpose(attn_out, perm=[0, 2, 1, 3])  \n",
    "        attn_out = tf.reshape(x, (batch_size, -1, d_model))  \n",
    "        attn_out = Dense(d_model)(attn_out)  \n",
    "        attn_out = Dropout(rate)(attn_out)\n",
    "        attn_out = BatchNormalization()(attn_out + x)\n",
    "        \n",
    "        fnn_out = Dense(dff, activation= 'relu')(attn_out)  # (batch_size, seq_len, dff)\n",
    "        fnn_out = Dense(d_model)(fnn_out)\n",
    "        fnn_out = Dropout(rate)(fnn_out)\n",
    "        x = BatchNormalization()(fnn_out + attn_out)\n",
    "        if i <= 1:\n",
    "            x = MaxPooling1D(2)(x)\n",
    "        else:\n",
    "            x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Dense(64)(x)\n",
    "    x = Flatten()(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Dense(output_dim, activation = 'sigmoid', name = 'label_out')(x)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = x)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:30:52.655747Z",
     "iopub.status.busy": "2021-02-05T05:30:52.653370Z",
     "iopub.status.idle": "2021-02-05T05:31:12.275944Z",
     "shell.execute_reply": "2021-02-05T05:31:12.276911Z"
    },
    "papermill": {
     "duration": 19.679257,
     "end_time": "2021-02-05T05:31:12.277109",
     "exception": false,
     "start_time": "2021-02-05T05:30:52.597852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = transformer_model(130 + 64 +88, 16, 128, 0, 3, 256, 4, 5)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/transformer_no_imputer_34_version2.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)\n",
    "\n",
    "model = transformer_model2(130 + 64 + 88, 16, 128, 0, 3, 256, 4, 5)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/transformer_no_imputer_45_version5.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)\n",
    "\n",
    "model = transformer_model2(130 + 64 +88, 16, 128, 0, 3, 256, 4, 5)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/transformer_no_imputer_55_version4.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:12.380468Z",
     "iopub.status.busy": "2021-02-05T05:31:12.379475Z",
     "iopub.status.idle": "2021-02-05T05:31:12.383525Z",
     "shell.execute_reply": "2021-02-05T05:31:12.382869Z"
    },
    "papermill": {
     "duration": 0.064639,
     "end_time": "2021-02-05T05:31:12.383672",
     "exception": false,
     "start_time": "2021-02-05T05:31:12.319033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, AveragePooling1D, MaxPooling1D, Flatten, Multiply, Add\n",
    "\n",
    "input_dim = 130 + 64 + 88\n",
    "output_dim = 5\n",
    "window_size = 16\n",
    "cha1 = 128\n",
    "cha2 = 256\n",
    "rate = 0.0\n",
    "\n",
    "\n",
    "def conv_model(input_dim, output_dim, window_size, cha1, cha2, rate):\n",
    "    inputs = Input(input_dim)\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(window_size * cha1, use_bias = False)(x)\n",
    "    x = tf.reshape(x, (-1, window_size, cha1))\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    for i in range(3):\n",
    "        #x = BatchNormalization()(x)\n",
    "        x = Dropout(rate)(x)\n",
    "        x = Conv1D(cha1, 3, activation = tf.keras.activations.swish, padding = 'causal')(x)\n",
    "        temp_x = x\n",
    "        \n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate)(x)\n",
    "        x = Conv1D(cha2, 3, activation = tf.keras.activations.swish, padding = 'causal')(x)\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate)(x)\n",
    "        x = Conv1D(cha1, 3, activation = tf.keras.activations.swish, padding = 'causal')(x)\n",
    "        \n",
    "        x = Add()([temp_x,x])\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "        \n",
    "    x = Dense(64)(x)    \n",
    "    x = Flatten()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Dense(output_dim, activation = 'sigmoid', name = 'label_out')(x)\n",
    "\n",
    "    \n",
    "    model = Model(inputs =inputs, outputs = x) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:12.484023Z",
     "iopub.status.busy": "2021-02-05T05:31:12.479785Z",
     "iopub.status.idle": "2021-02-05T05:31:31.277706Z",
     "shell.execute_reply": "2021-02-05T05:31:31.276856Z"
    },
    "papermill": {
     "duration": 18.851351,
     "end_time": "2021-02-05T05:31:31.277860",
     "exception": false,
     "start_time": "2021-02-05T05:31:12.426509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = conv_model(input_dim, output_dim, window_size, cha1, cha2, rate)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/conv_model3_42_3.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)    \n",
    "\n",
    "model = conv_model(input_dim, output_dim, window_size, cha1, cha2, rate)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/conv_model5_42_4.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)    \n",
    "\n",
    "model = conv_model(input_dim, output_dim, window_size, cha1, cha2, rate)\n",
    "model.load_weights(f'../input/js-non-of-model-w-sae/conv_model4_42_5.hdf5')\n",
    "if not TRAINING:\n",
    "    model = LiteModel.from_keras_model(model)\n",
    "models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:31.379420Z",
     "iopub.status.busy": "2021-02-05T05:31:31.377345Z",
     "iopub.status.idle": "2021-02-05T05:31:31.384547Z",
     "shell.execute_reply": "2021-02-05T05:31:31.385109Z"
    },
    "papermill": {
     "duration": 0.065488,
     "end_time": "2021-02-05T05:31:31.385454",
     "exception": false,
     "start_time": "2021-02-05T05:31:31.319966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim,output_dim):\n",
    "    inputs = Input(input_dim)\n",
    "    \n",
    "    #x = encoder(inputs)\n",
    "    #x = Concatenate()([x,inputs]) #use both raw and encoded features\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "    x1 = Dense(256)(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Lambda(tf.keras.activations.swish)(x1)\n",
    "    x1 = Dropout(0.2)(x1)    \n",
    "    \n",
    "    x2 = Concatenate()([x1, x])\n",
    "    x2 = Dense(256)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Lambda(tf.keras.activations.swish)(x2)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "\n",
    "    x3 = Concatenate()([x2, x1])\n",
    "    x3 = Dense(256)(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Lambda(tf.keras.activations.swish)(x3)\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    \n",
    "    x4 = Concatenate()([x3, x2])\n",
    "    x4 = Dense(256)(x4)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Lambda(tf.keras.activations.swish)(x4)\n",
    "    x4 = Dropout(0.2)(x4)\n",
    "    \n",
    "    x = Concatenate()([x4, x3])\n",
    "    \n",
    "    x = Dense(output_dim,activation='sigmoid', name = 'label_output')(x)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:31.484737Z",
     "iopub.status.busy": "2021-02-05T05:31:31.484014Z",
     "iopub.status.idle": "2021-02-05T05:31:45.491573Z",
     "shell.execute_reply": "2021-02-05T05:31:45.490933Z"
    },
    "papermill": {
     "duration": 14.064343,
     "end_time": "2021-02-05T05:31:45.491723",
     "exception": false,
     "start_time": "2021-02-05T05:31:31.427380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in range(3,6):\n",
    "    model = create_model(130 + 64 + 88, 5)\n",
    "    model.load_weights(f'../input/js-non-of-model-w-sae/resnet_model_{f}.hdf5')\n",
    "    if not TRAINING:\n",
    "        model = LiteModel.from_keras_model(model)\n",
    "    models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:45.592575Z",
     "iopub.status.busy": "2021-02-05T05:31:45.591798Z",
     "iopub.status.idle": "2021-02-05T05:31:45.594212Z",
     "shell.execute_reply": "2021-02-05T05:31:45.594741Z"
    },
    "papermill": {
     "duration": 0.058958,
     "end_time": "2021-02-05T05:31:45.594888",
     "exception": false,
     "start_time": "2021-02-05T05:31:45.535930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    print('Loading...')\n",
    "    train = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\n",
    "    TARGET = 'action'\n",
    "    FEATS = ['feature_{}'.format(int(i)) for i in range(130)]\n",
    "\n",
    "    print('Filling...')\n",
    "    train = train.query('weight > 0').reset_index(drop = True)\n",
    "    resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "    y = np.stack([(train[c] > 0.00000).astype('int') for c in resp_cols]).T\n",
    "    X = train[FEATS].to_numpy()\n",
    "    wr = train.weight*train['resp'].to_numpy()\n",
    "    date = train['date'].values\n",
    "    print('Finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:45.684406Z",
     "iopub.status.busy": "2021-02-05T05:31:45.683672Z",
     "iopub.status.idle": "2021-02-05T05:31:45.712090Z",
     "shell.execute_reply": "2021-02-05T05:31:45.711440Z"
    },
    "papermill": {
     "duration": 0.074519,
     "end_time": "2021-02-05T05:31:45.712257",
     "exception": false,
     "start_time": "2021-02-05T05:31:45.637738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nan_feat_bool = pd.read_pickle('../input/nn-model-wpt/nfb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:45.809820Z",
     "iopub.status.busy": "2021-02-05T05:31:45.808777Z",
     "iopub.status.idle": "2021-02-05T05:31:45.812654Z",
     "shell.execute_reply": "2021-02-05T05:31:45.813214Z"
    },
    "papermill": {
     "duration": 0.055895,
     "end_time": "2021-02-05T05:31:45.813391",
     "exception": false,
     "start_time": "2021-02-05T05:31:45.757496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    with open('../input/js-cv-split2/f_mean.npy', 'rb') as f:\n",
    "        f_mean = np.load(f)\n",
    "    mask2 = np.isnan(X[:,nan_feat_bool]).astype(int)\n",
    "    X = np.nan_to_num(X) + np.isnan(X).astype(int) * f_mean\n",
    "    del(train)\n",
    "    _= gc.collect()\n",
    "    splits = pd.read_pickle('../input/js-cv-split2/cross_validation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:45.911806Z",
     "iopub.status.busy": "2021-02-05T05:31:45.910753Z",
     "iopub.status.idle": "2021-02-05T05:31:45.915095Z",
     "shell.execute_reply": "2021-02-05T05:31:45.914531Z"
    },
    "papermill": {
     "duration": 0.056235,
     "end_time": "2021-02-05T05:31:45.915257",
     "exception": false,
     "start_time": "2021-02-05T05:31:45.859022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    X_test = X[splits[3][1]]\n",
    "    y_test = y[splits[3][1]]\n",
    "    mask_test = mask2[splits[3][1]]\n",
    "    encoded_X_test = encoder(X_test).numpy()\n",
    "    X_test = np.concatenate((X_test, encoded_X_test, mask_test), axis = -1)\n",
    "    date_test = date[splits[3][1]]\n",
    "    wr_test = wr[splits[3][1]]\n",
    "    del(mask_test)\n",
    "    _= gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.010799Z",
     "iopub.status.busy": "2021-02-05T05:31:46.009577Z",
     "iopub.status.idle": "2021-02-05T05:31:46.014067Z",
     "shell.execute_reply": "2021-02-05T05:31:46.013278Z"
    },
    "papermill": {
     "duration": 0.056334,
     "end_time": "2021-02-05T05:31:46.014293",
     "exception": false,
     "start_time": "2021-02-05T05:31:45.957959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred):\n",
    "    Pi = np.bincount(y_true, y_pred)\n",
    "    unique_y_true = np.unique(y_true).tolist()\n",
    "    Pi = Pi[unique_y_true]\n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / len(Pi))\n",
    "    u = min(max(t, 0), 6) * np.sum(Pi)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.108414Z",
     "iopub.status.busy": "2021-02-05T05:31:46.107694Z",
     "iopub.status.idle": "2021-02-05T05:31:46.112495Z",
     "shell.execute_reply": "2021-02-05T05:31:46.111016Z"
    },
    "papermill": {
     "duration": 0.054653,
     "end_time": "2021-02-05T05:31:46.112647",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.057994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    Y_hat = [model.predict(X_test, batch_size = 10000) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.213068Z",
     "iopub.status.busy": "2021-02-05T05:31:46.212321Z",
     "iopub.status.idle": "2021-02-05T05:31:46.215019Z",
     "shell.execute_reply": "2021-02-05T05:31:46.215579Z"
    },
    "papermill": {
     "duration": 0.058379,
     "end_time": "2021-02-05T05:31:46.215747",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.157368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat[0] + x2 * Y_hat[3] + x3*Y_hat[6] + x4 * Y_hat[9] + x5 * Y_hat[12], axis = 1) > 0.5,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.307257Z",
     "iopub.status.busy": "2021-02-05T05:31:46.306516Z",
     "iopub.status.idle": "2021-02-05T05:31:46.318494Z",
     "shell.execute_reply": "2021-02-05T05:31:46.317837Z"
    },
    "papermill": {
     "duration": 0.059662,
     "end_time": "2021-02-05T05:31:46.318645",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.258983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat[0] + x2 * Y_hat[3] + x3*Y_hat[6] + x4 * Y_hat[9] + x5 * Y_hat[12], axis = 1) > 0.501,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.419199Z",
     "iopub.status.busy": "2021-02-05T05:31:46.418224Z",
     "iopub.status.idle": "2021-02-05T05:31:46.421858Z",
     "shell.execute_reply": "2021-02-05T05:31:46.422537Z"
    },
    "papermill": {
     "duration": 0.060344,
     "end_time": "2021-02-05T05:31:46.422726",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.362382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat[0] + x2 * Y_hat[3] + x3*Y_hat[6] + x4 * Y_hat[9] + x5 * Y_hat[12], axis = 1) > 0.502,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.526734Z",
     "iopub.status.busy": "2021-02-05T05:31:46.525772Z",
     "iopub.status.idle": "2021-02-05T05:31:46.530329Z",
     "shell.execute_reply": "2021-02-05T05:31:46.529421Z"
    },
    "papermill": {
     "duration": 0.062163,
     "end_time": "2021-02-05T05:31:46.530486",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.468323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat[0] + x2 * Y_hat[3] + x3*Y_hat[6] + x4 * Y_hat[9] + x5 * Y_hat[12], axis = 1) > 0.503,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.633363Z",
     "iopub.status.busy": "2021-02-05T05:31:46.632059Z",
     "iopub.status.idle": "2021-02-05T05:31:46.635186Z",
     "shell.execute_reply": "2021-02-05T05:31:46.635699Z"
    },
    "papermill": {
     "duration": 0.060537,
     "end_time": "2021-02-05T05:31:46.635886",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.575349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat[0] + x2 * Y_hat[3] + x3*Y_hat[6] + x4 * Y_hat[9] + x5 * Y_hat[12], axis = 1) > 0.504,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.736903Z",
     "iopub.status.busy": "2021-02-05T05:31:46.736089Z",
     "iopub.status.idle": "2021-02-05T05:31:46.740002Z",
     "shell.execute_reply": "2021-02-05T05:31:46.739284Z"
    },
    "papermill": {
     "duration": 0.060204,
     "end_time": "2021-02-05T05:31:46.740157",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.679953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat[0] + x2 * Y_hat[3] + x3*Y_hat[6] + x4 * Y_hat[9] + x5 * Y_hat[12], axis = 1) > 0.505,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.840925Z",
     "iopub.status.busy": "2021-02-05T05:31:46.840164Z",
     "iopub.status.idle": "2021-02-05T05:31:46.842493Z",
     "shell.execute_reply": "2021-02-05T05:31:46.843121Z"
    },
    "papermill": {
     "duration": 0.058639,
     "end_time": "2021-02-05T05:31:46.843328",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.784689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat[0] + x2 * Y_hat[3] + x3*Y_hat[6] + x4 * Y_hat[9] + x5 * Y_hat[12], axis = 1) > 0.506,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:46.935673Z",
     "iopub.status.busy": "2021-02-05T05:31:46.934814Z",
     "iopub.status.idle": "2021-02-05T05:31:46.944918Z",
     "shell.execute_reply": "2021-02-05T05:31:46.945540Z"
    },
    "papermill": {
     "duration": 0.058266,
     "end_time": "2021-02-05T05:31:46.945743",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.887477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat[0] + x2 * Y_hat[3] + x3*Y_hat[6] + x4 * Y_hat[9] + x5 * Y_hat[12], axis = 1) > 0.507,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.038678Z",
     "iopub.status.busy": "2021-02-05T05:31:47.037756Z",
     "iopub.status.idle": "2021-02-05T05:31:47.048221Z",
     "shell.execute_reply": "2021-02-05T05:31:47.048794Z"
    },
    "papermill": {
     "duration": 0.05899,
     "end_time": "2021-02-05T05:31:47.048996",
     "exception": false,
     "start_time": "2021-02-05T05:31:46.990006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat[0] + x2 * Y_hat[3] + x3*Y_hat[6] + x4 * Y_hat[9] + x5 * Y_hat[12], axis = 1) > 0.508,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.143556Z",
     "iopub.status.busy": "2021-02-05T05:31:47.142643Z",
     "iopub.status.idle": "2021-02-05T05:31:47.150354Z",
     "shell.execute_reply": "2021-02-05T05:31:47.150935Z"
    },
    "papermill": {
     "duration": 0.056802,
     "end_time": "2021-02-05T05:31:47.151113",
     "exception": false,
     "start_time": "2021-02-05T05:31:47.094311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    X_test = X[splits[4][1]]\n",
    "    y_test = y[splits[4][1]]\n",
    "    mask_test = mask2[splits[4][1]]\n",
    "    encoded_X_test = encoder(X_test).numpy()\n",
    "    X_test = np.concatenate((X_test, encoded_X_test, mask_test), axis = -1)\n",
    "    date_test = date[splits[4][1]]\n",
    "    wr_test = wr[splits[4][1]]\n",
    "    del(mask_test)\n",
    "    _= gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.245302Z",
     "iopub.status.busy": "2021-02-05T05:31:47.244573Z",
     "iopub.status.idle": "2021-02-05T05:31:47.249221Z",
     "shell.execute_reply": "2021-02-05T05:31:47.249728Z"
    },
    "papermill": {
     "duration": 0.053693,
     "end_time": "2021-02-05T05:31:47.249908",
     "exception": false,
     "start_time": "2021-02-05T05:31:47.196215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    Y_hat1 = [model.predict(X_test, batch_size = 10000) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.350289Z",
     "iopub.status.busy": "2021-02-05T05:31:47.349119Z",
     "iopub.status.idle": "2021-02-05T05:31:47.357897Z",
     "shell.execute_reply": "2021-02-05T05:31:47.357125Z"
    },
    "papermill": {
     "duration": 0.06308,
     "end_time": "2021-02-05T05:31:47.358038",
     "exception": false,
     "start_time": "2021-02-05T05:31:47.294958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat1[1] + x2 * Y_hat1[4] + x3*Y_hat1[7] + x4 * Y_hat1[10] + x5 * Y_hat1[13], axis = 1) > 0.5,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.453403Z",
     "iopub.status.busy": "2021-02-05T05:31:47.452621Z",
     "iopub.status.idle": "2021-02-05T05:31:47.463152Z",
     "shell.execute_reply": "2021-02-05T05:31:47.463679Z"
    },
    "papermill": {
     "duration": 0.060183,
     "end_time": "2021-02-05T05:31:47.463869",
     "exception": false,
     "start_time": "2021-02-05T05:31:47.403686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat1[1] + x2 * Y_hat1[4] + x3*Y_hat1[7] + x4 * Y_hat1[10] + x5 * Y_hat1[13], axis = 1) > 0.501,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.569448Z",
     "iopub.status.busy": "2021-02-05T05:31:47.568641Z",
     "iopub.status.idle": "2021-02-05T05:31:47.571040Z",
     "shell.execute_reply": "2021-02-05T05:31:47.571566Z"
    },
    "papermill": {
     "duration": 0.060999,
     "end_time": "2021-02-05T05:31:47.571754",
     "exception": false,
     "start_time": "2021-02-05T05:31:47.510755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat1[1] + x2 * Y_hat1[4] + x3*Y_hat1[7] + x4 * Y_hat1[10] + x5 * Y_hat1[13], axis = 1) > 0.502,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.667308Z",
     "iopub.status.busy": "2021-02-05T05:31:47.666602Z",
     "iopub.status.idle": "2021-02-05T05:31:47.677066Z",
     "shell.execute_reply": "2021-02-05T05:31:47.677674Z"
    },
    "papermill": {
     "duration": 0.059651,
     "end_time": "2021-02-05T05:31:47.677844",
     "exception": false,
     "start_time": "2021-02-05T05:31:47.618193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat1[1] + x2 * Y_hat1[4] + x3*Y_hat1[7] + x4 * Y_hat1[10] + x5 * Y_hat1[13], axis = 1) > 0.503,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.772204Z",
     "iopub.status.busy": "2021-02-05T05:31:47.771511Z",
     "iopub.status.idle": "2021-02-05T05:31:47.782594Z",
     "shell.execute_reply": "2021-02-05T05:31:47.783387Z"
    },
    "papermill": {
     "duration": 0.060526,
     "end_time": "2021-02-05T05:31:47.783577",
     "exception": false,
     "start_time": "2021-02-05T05:31:47.723051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat1[1] + x2 * Y_hat1[4] + x3*Y_hat1[7] + x4 * Y_hat1[10] + x5 * Y_hat1[13], axis = 1) > 0.504,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.881278Z",
     "iopub.status.busy": "2021-02-05T05:31:47.880543Z",
     "iopub.status.idle": "2021-02-05T05:31:47.890847Z",
     "shell.execute_reply": "2021-02-05T05:31:47.891601Z"
    },
    "papermill": {
     "duration": 0.061049,
     "end_time": "2021-02-05T05:31:47.891787",
     "exception": false,
     "start_time": "2021-02-05T05:31:47.830738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat1[1] + x2 * Y_hat1[4] + x3*Y_hat1[7] + x4 * Y_hat1[10] + x5 * Y_hat1[13], axis = 1) > 0.505,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:47.986624Z",
     "iopub.status.busy": "2021-02-05T05:31:47.985849Z",
     "iopub.status.idle": "2021-02-05T05:31:47.996938Z",
     "shell.execute_reply": "2021-02-05T05:31:47.997548Z"
    },
    "papermill": {
     "duration": 0.060439,
     "end_time": "2021-02-05T05:31:47.997725",
     "exception": false,
     "start_time": "2021-02-05T05:31:47.937286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat1[1] + x2 * Y_hat1[4] + x3*Y_hat1[7] + x4 * Y_hat1[10] + x5 * Y_hat1[13], axis = 1) > 0.506,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:48.093705Z",
     "iopub.status.busy": "2021-02-05T05:31:48.092769Z",
     "iopub.status.idle": "2021-02-05T05:31:48.103529Z",
     "shell.execute_reply": "2021-02-05T05:31:48.104197Z"
    },
    "papermill": {
     "duration": 0.060697,
     "end_time": "2021-02-05T05:31:48.104383",
     "exception": false,
     "start_time": "2021-02-05T05:31:48.043686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat1[1] + x2 * Y_hat1[4] + x3*Y_hat1[7] + x4 * Y_hat1[10] + x5 * Y_hat1[13], axis = 1) > 0.507,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:48.202238Z",
     "iopub.status.busy": "2021-02-05T05:31:48.201466Z",
     "iopub.status.idle": "2021-02-05T05:31:48.211811Z",
     "shell.execute_reply": "2021-02-05T05:31:48.212595Z"
    },
    "papermill": {
     "duration": 0.060663,
     "end_time": "2021-02-05T05:31:48.212780",
     "exception": false,
     "start_time": "2021-02-05T05:31:48.152117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat1[1] + x2 * Y_hat1[4] + x3*Y_hat1[7] + x4 * Y_hat1[10] + x5 * Y_hat1[13], axis = 1) > 0.508,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:48.310799Z",
     "iopub.status.busy": "2021-02-05T05:31:48.310029Z",
     "iopub.status.idle": "2021-02-05T05:31:48.317281Z",
     "shell.execute_reply": "2021-02-05T05:31:48.317774Z"
    },
    "papermill": {
     "duration": 0.057481,
     "end_time": "2021-02-05T05:31:48.317950",
     "exception": false,
     "start_time": "2021-02-05T05:31:48.260469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    X_test = X[splits[5][1]]\n",
    "    y_test = y[splits[5][1]]\n",
    "    mask_test = mask2[splits[5][1]]\n",
    "    encoded_X_test = encoder(X_test).numpy()\n",
    "    X_test = np.concatenate((X_test, encoded_X_test, mask_test), axis = -1)\n",
    "    date_test = date[splits[5][1]]\n",
    "    wr_test = wr[splits[5][1]]\n",
    "    del(mask_test)\n",
    "    _= gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:48.416156Z",
     "iopub.status.busy": "2021-02-05T05:31:48.415424Z",
     "iopub.status.idle": "2021-02-05T05:31:48.419838Z",
     "shell.execute_reply": "2021-02-05T05:31:48.420586Z"
    },
    "papermill": {
     "duration": 0.056025,
     "end_time": "2021-02-05T05:31:48.420775",
     "exception": false,
     "start_time": "2021-02-05T05:31:48.364750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    Y_hat2 = [model.predict(X_test, batch_size = 10000) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:48.517963Z",
     "iopub.status.busy": "2021-02-05T05:31:48.517235Z",
     "iopub.status.idle": "2021-02-05T05:31:48.528399Z",
     "shell.execute_reply": "2021-02-05T05:31:48.529034Z"
    },
    "papermill": {
     "duration": 0.061612,
     "end_time": "2021-02-05T05:31:48.529239",
     "exception": false,
     "start_time": "2021-02-05T05:31:48.467627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat2[2] + x2 * Y_hat2[5] + x3*Y_hat2[8] + x4 * Y_hat2[11] + x5 * Y_hat2[14], axis = 1) > 0.5,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:48.638976Z",
     "iopub.status.busy": "2021-02-05T05:31:48.637871Z",
     "iopub.status.idle": "2021-02-05T05:31:48.640909Z",
     "shell.execute_reply": "2021-02-05T05:31:48.640349Z"
    },
    "papermill": {
     "duration": 0.061873,
     "end_time": "2021-02-05T05:31:48.641045",
     "exception": false,
     "start_time": "2021-02-05T05:31:48.579172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat2[2] + x2 * Y_hat2[5] + x3*Y_hat2[8] + x4 * Y_hat2[11] + x5 * Y_hat2[14], axis = 1) > 0.501,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:48.748687Z",
     "iopub.status.busy": "2021-02-05T05:31:48.746061Z",
     "iopub.status.idle": "2021-02-05T05:31:48.753226Z",
     "shell.execute_reply": "2021-02-05T05:31:48.752573Z"
    },
    "papermill": {
     "duration": 0.065371,
     "end_time": "2021-02-05T05:31:48.753358",
     "exception": false,
     "start_time": "2021-02-05T05:31:48.687987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat2[2] + x2 * Y_hat2[5] + x3*Y_hat2[8] + x4 * Y_hat2[11] + x5 * Y_hat2[14], axis = 1) > 0.502,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:48.862632Z",
     "iopub.status.busy": "2021-02-05T05:31:48.860259Z",
     "iopub.status.idle": "2021-02-05T05:31:48.866249Z",
     "shell.execute_reply": "2021-02-05T05:31:48.865507Z"
    },
    "papermill": {
     "duration": 0.065444,
     "end_time": "2021-02-05T05:31:48.866382",
     "exception": false,
     "start_time": "2021-02-05T05:31:48.800938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat2[2] + x2 * Y_hat2[5] + x3*Y_hat2[8] + x4 * Y_hat2[11] + x5 * Y_hat2[14], axis = 1) > 0.503,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:48.968527Z",
     "iopub.status.busy": "2021-02-05T05:31:48.967861Z",
     "iopub.status.idle": "2021-02-05T05:31:48.979538Z",
     "shell.execute_reply": "2021-02-05T05:31:48.980049Z"
    },
    "papermill": {
     "duration": 0.064432,
     "end_time": "2021-02-05T05:31:48.980250",
     "exception": false,
     "start_time": "2021-02-05T05:31:48.915818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat2[2] + x2 * Y_hat2[5] + x3*Y_hat2[8] + x4 * Y_hat2[11] + x5 * Y_hat2[14], axis = 1) > 0.504,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:49.085242Z",
     "iopub.status.busy": "2021-02-05T05:31:49.084517Z",
     "iopub.status.idle": "2021-02-05T05:31:49.091647Z",
     "shell.execute_reply": "2021-02-05T05:31:49.090856Z"
    },
    "papermill": {
     "duration": 0.065123,
     "end_time": "2021-02-05T05:31:49.091796",
     "exception": false,
     "start_time": "2021-02-05T05:31:49.026673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat2[2] + x2 * Y_hat2[5] + x3*Y_hat2[8] + x4 * Y_hat2[11] + x5 * Y_hat2[14], axis = 1) > 0.505,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:49.194338Z",
     "iopub.status.busy": "2021-02-05T05:31:49.193635Z",
     "iopub.status.idle": "2021-02-05T05:31:49.204350Z",
     "shell.execute_reply": "2021-02-05T05:31:49.204941Z"
    },
    "papermill": {
     "duration": 0.064455,
     "end_time": "2021-02-05T05:31:49.205093",
     "exception": false,
     "start_time": "2021-02-05T05:31:49.140638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat2[2] + x2 * Y_hat2[5] + x3*Y_hat2[8] + x4 * Y_hat2[11] + x5 * Y_hat2[14], axis = 1) > 0.506,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:49.307490Z",
     "iopub.status.busy": "2021-02-05T05:31:49.306806Z",
     "iopub.status.idle": "2021-02-05T05:31:49.318045Z",
     "shell.execute_reply": "2021-02-05T05:31:49.318637Z"
    },
    "papermill": {
     "duration": 0.065977,
     "end_time": "2021-02-05T05:31:49.318817",
     "exception": false,
     "start_time": "2021-02-05T05:31:49.252840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat2[2] + x2 * Y_hat2[5] + x3*Y_hat2[8] + x4 * Y_hat2[11] + x5 * Y_hat2[14], axis = 1) > 0.507,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:49.424661Z",
     "iopub.status.busy": "2021-02-05T05:31:49.423936Z",
     "iopub.status.idle": "2021-02-05T05:31:49.437410Z",
     "shell.execute_reply": "2021-02-05T05:31:49.436835Z"
    },
    "papermill": {
     "duration": 0.07011,
     "end_time": "2021-02-05T05:31:49.437543",
     "exception": false,
     "start_time": "2021-02-05T05:31:49.367433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    best3 = 0\n",
    "    for i in range(10000):\n",
    "        x1 = np.random.uniform()\n",
    "        x2 = np.random.uniform()\n",
    "        x3 = np.random.uniform()\n",
    "        x4 = np.random.uniform()\n",
    "        x5 = np.random.uniform()\n",
    "        #x3 = np.random.uniform(0.48,0.52)\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "        x1 /= x\n",
    "        x2 /= x\n",
    "        x3 /= x\n",
    "        x4 /= x\n",
    "        x5 /= x\n",
    "        \n",
    "        score3 = metrics(date_test,wr_test*np.where(np.median(x1 * Y_hat2[2] + x2 * Y_hat2[5] + x3*Y_hat2[8] + x4 * Y_hat2[11] + x5 * Y_hat2[14], axis = 1) > 0.508,1,0) )\n",
    "        if score3 > best3:\n",
    "            best3 = score3\n",
    "            print(x1, x2, x3, x4, x5, best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:49.538407Z",
     "iopub.status.busy": "2021-02-05T05:31:49.537741Z",
     "iopub.status.idle": "2021-02-05T05:31:49.546721Z",
     "shell.execute_reply": "2021-02-05T05:31:49.547341Z"
    },
    "papermill": {
     "duration": 0.063186,
     "end_time": "2021-02-05T05:31:49.547495",
     "exception": false,
     "start_time": "2021-02-05T05:31:49.484309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../input/js-cv-split2/f_mean.npy', 'rb') as f:\n",
    "    f_mean = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:49.650579Z",
     "iopub.status.busy": "2021-02-05T05:31:49.649851Z",
     "iopub.status.idle": "2021-02-05T05:31:53.605073Z",
     "shell.execute_reply": "2021-02-05T05:31:53.604467Z"
    },
    "papermill": {
     "duration": 4.008092,
     "end_time": "2021-02-05T05:31:53.605263",
     "exception": false,
     "start_time": "2021-02-05T05:31:49.597171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = LiteModel.from_keras_model(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T05:31:53.718634Z",
     "iopub.status.busy": "2021-02-05T05:31:53.712889Z",
     "iopub.status.idle": "2021-02-05T05:37:19.974567Z",
     "shell.execute_reply": "2021-02-05T05:37:19.973956Z"
    },
    "papermill": {
     "duration": 326.319891,
     "end_time": "2021-02-05T05:37:19.974719",
     "exception": false,
     "start_time": "2021-02-05T05:31:53.654828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37913d053ff04090b20e4892b2ce9351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not TRAINING:\n",
    "    import janestreet\n",
    "    env = janestreet.make_env()\n",
    "    th = 0.505\n",
    "    #501\n",
    "    #w_th = [0.282586165396963,0,0,0.409453626674629,0.230074696487854,0.601781674485216,0,0,0.0116348575038513,0.243247292748396,0.439550808680961,0,0.0647129151800104,0.330374494831183,0.386583468010932]\n",
    "    #502\n",
    "    #w_th = [0.350562125298993,0,0,0.448576828126836,0.134586453380421,0.65264356621618,0,0,0.0261123909009704,0.134511467677107,0.685961342574953,0,0.0663495788970628,0.179452204044625,0.321244042882849]\n",
    "    #503\n",
    "    #w_th = [0.360800665430468,0,0,0.429149764044411,0.114599310364374,0.69178947541075,0,0,0.0682843624963087,0.120513849928649,0.830006826443837,0,0.0895357205964704,0.0553938631917881,0.23992616209294]\n",
    "    #504\n",
    "    #w_th = [0.440453769182776,0,0,0.386035526242392,0.0947024403089371,0.761301979742291,0,0,0.0825679577912019,0.159692569362111,0.869504966116743,0,0.0138181352127204,0.0357925935743198,0.156130062466506]\n",
    "    #505\n",
    "    #w_th = [0.0160982113917282,0,0,0.408031763680652,0.103234899296302,0.770207288773767,0,0,0.129126332662569,0.556117716944014,0.864208099260292,0,0.0197523079836051,0.0325570014434044,0.100666378563663]\n",
    "    #506\n",
    "    #w_th = [0.0107694490518132,0,0,0.418049733705931,0.168603910678253,0.737750099082452,0,0,0.244939753415722,0.417596620720282,0.759687963502009,0,0.153584196521972,0.0717081258197375,0.0173101475018251]\n",
    "    #507\n",
    "    #w_th = [0.00869530976805593,0,0,0.43934692714842,0.0647559713228543,0.544669476464809,0,0,0.262487538642279,0.344704322163479,0.718182476512787,0,0.207253440920044,0.217061552164358,0.192842984892911]\n",
    "    #508\n",
    "    #w_th = [0.0432387797581322,0,0,0.346699406169769,0.116159401563698,0.0913701656245924,0,0,0.35951130675128,0.476263938176473,0.774953192987766,0,0.133797875895625,0.108887405448535,0.549118527624126]\n",
    "    \n",
    "    #w_th_boolen = (np.array(w_th) > 0).tolist()\n",
    "    #w_th = [i for (i, v) in zip(w_th, w_th_boolen) if v]\n",
    "    #models = [i for (i, v) in zip(models, w_th_boolen) if v]\n",
    "    for (test_df, pred_df) in tqdm(env.iter_test()):\n",
    "        if test_df['weight'].item() > 0:\n",
    "            #test_df[FIX_FEAT] = pt.transform(test_df[FIX_FEAT].values)\n",
    "            x_tt = test_df.loc[:, FEATS].values\n",
    "            mask = np.isnan(x_tt[:,nan_feat_bool]).astype(np.int8)\n",
    "            if np.isnan(x_tt.sum()):\n",
    "\n",
    "                x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt).astype(np.int8) * f_mean\n",
    "                \n",
    "            x_tt = x_tt.astype(np.float32)\n",
    "            encoded_x = encoder.predict_single2(x_tt)\n",
    "            x_tt = tf.concat([x_tt, encoded_x, mask], axis = -1)\n",
    "            #0.5\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.269289583638586,0.140273060522882,0.00431820575329026,0.410287705610988,0.248819727362426,0.930825875759512,0.0745530246350113,0.28684450294532,0.0398643375719953,0.245869686115413,0.32406270916937,0.0249915809152021])\n",
    "            #0.501\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.0763251457522784,0.0788625175166904,0.189492504605759,0.341901274112498,0.247725213614468,0.655959549587888,0.0187377150341519,0.240186716116674,0.143356259279585,0.56303586510107,0.433225552752167,0.0111916865267664])\n",
    "            #0.502\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.0576583473691916,0.12255652240959,0.175323289611383,0.449173119701892,0.110027096104041,0.76522980391606,0.26055588039915,0.00275766092980543,0.0589500766202904,0.232612652529765,0.764658720556562,0.000496829852265645])\n",
    "            #0.503\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.00870004211860127,0.0978252692956878,0.298014718855447,0.383586287383453,0.100620814834676,0.620239671826976,0.0867980001869826,0.0179772830228647,0.071241936891379,0.520915670310963,0.783576632846771,0.0105036724261971])\n",
    "            #0.504\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.0900695070920216,0.0400101879000951,0.363508444081315,0.404165368235183,0.101581732824844,0.52280927277972,0.0766822336375494,0.0223235719877681,0.0813574399335528,0.429082891035245,0.836084507287292,0.0323248432054112])\n",
    "            #0.505\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.14585293948777,0.0321340599888603,0.168930356391904,0.45014880680078,0.0928682653923039,0.483209333358805,0.206996385495624,0.0014347064763478,0.195922871036136,0.197001868215824,0.873562968142487,0.151937439213153])\n",
    "            \n",
    "            #0.506\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.123190243224635,0.0333809356163824,0.223927230959407,0.4083891129262,0.214877194263553,0.488523934898997,0.115077478026766,0.274629118750788,0.230760689860318,0.353343165822397,0.477112751369275,0.0567881442812759])\n",
    "            #0.507\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.0792840481940689,0.0486631725897758,0.088028800771282,0.413007787518532,0.180887357608131,0.59477504438469,0.143226402099234,0.307389347262816,0.315100337014842,0.364481762188163,0.463060122539277,0.00209581782918519])\n",
    "            #0.508\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.104034154023355,0.00943763699276361,0.0345839554383715,0.436273484206495,0.186711622897726,0.420741558536897,0.142822556506646,0.365700918525257,0.0200891010652324,0.316869805263502,0.438149821584252,0.524585384959498])\n",
    "            #0.509\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.120926552448402,0.0428807234778378,0.316305249359201,0.32172273862087,0.250142935175495,0.241626069167982,0.132838781409683,0.365697181864785,0.397642473806075,0.424511927521044,0.341279159481881,0.0444262076667411])\n",
    "            #0.51\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.26694818048737,0.00541709707387954,0.283017229351308,0.378816459431733,0.266689820694482,0.269084127637271,0.0883274830502573,0.716043337455058,0.432078909025282,0.265907877030638,0.0118497447765794,0.0158197339861377])\n",
    "            #test \n",
    "            \n",
    "            #15 models\n",
    "            #0.5\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.00660530146858248,0.0195375928683106,0.182872045891882,0.260118264684016,0.259382986465131,0.553270253699695,0.0166969213150559,0.0154832176142514,0.0198471979821222,0.47617786468772,0.299282816507157,0.00360026847919924,0.240401647844624,0.406313386545149,0.2404102339471])\n",
    "            #0.501\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.336580956009717,0.085371165319604,0.00218059361783603,0.373457256322469,0.162088571157434,0.525977250550515,0.018854173902929,0.023271705478133,0.000476500288030846,0.122090501937807,0.225064973272897,0.0293346148533625,0.149017111827077,0.50420358477193,0.442031040690255])\n",
    "            #0.502\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.267630393363895,0.0121074000206929,0.077325505585401,0.459718152232472,0.23373410136094,0.511652365670948,0.00478935684023983,0.109150725044656,0.0252773717038874,0.140126052877474,0.28370351248071,0.0120077947696216,0.127736044685916,0.361304261092999,0.373736962270141])\n",
    "            #0.503\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.372400399851216,0.0842449434986123,0.00582403783490785,0.356247458832398,0.127812090578148,0.384425132524302,0.00461311509458511,0.0452318385342215,0.00376762080572573,0.12848525414531,0.680780700868442,0.22207416523498,0.138253772076489,0.0619304265205752,0.383909043600083])\n",
    "            #0.504\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.0314205579910957,0.0179271771151849,0.0567105407619044,0.232853546367987,0.1566876188777,0.201552569532505,0.204970454836834,0.0574374672227673,0.05168700098273,0.49925730930842,0.661029894181915,0.0616861543090878,0.0314981314956622,0.106917842602431,0.628363734413771])\n",
    "            #0.505\n",
    "            pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.30643427242264,0.209491777667095,0.137817458159022,0.406721405697375,0.286242301004577,0.471708329957434,0.0803022608268741,0.190720619919767,0.157722275768748,0.169601431361634,0.185827274674314,0.21853027424372,0.0369406296914762,0.127718026734245,0.0142216618710743])\n",
    "            #0.506\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.000488861162908858,0.0313966987398687,0.0656565676638678,0.347998116798586,0.228480791106072,0.341137346186518,0.157814581352585,0.29812125283193,0.0493706636969972,0.394416638844336,0.437189210728981,0.0695625253674544,0.0992818018415826,0.00481204659314628,0.474272897085161])\n",
    "            #0.507\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.0203769850068616,0.114490385313229,0.0707570701624141,0.385520860294775,0.0759857589733933,0.348705206822549,0.0612651093612269,0.0345871704494746,0.0853170582856602,0.403623242658935,0.622493080241552,0.110674275844068,0.1292138026782,0.152443605022349,0.384546388885307])\n",
    "            #0.508\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [0.0439711805548865,0.0188827744980941,0.121000832077844,0.358214855147226,0.164080208761975,0.213987041979311,0.0588312916190743,0.332702641908083,0.0410097981416294,0.392269323193152,0.460821755585347,0.286801020156277,0.146713349485659,0.0235126192464997,0.337201307644937])\n",
    "            \n",
    "            \n",
    "            \n",
    "            #501 skipped\n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = w_th)\n",
    "            \n",
    "            #pred = np.average([model.predict_single2(x_tt) for model in models], axis = 0, weights = [1]*15)\n",
    "            pred = np.median(pred)\n",
    "            pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n",
    "        else:\n",
    "            pred_df.action = 0\n",
    "        env.predict(pred_df) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 443.965033,
   "end_time": "2021-02-05T05:37:20.135550",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-05T05:29:56.170517",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "37913d053ff04090b20e4892b2ce9351": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_875c68685bb74e1ca7a2abb798e2a465",
        "IPY_MODEL_63a41a99f89544619d1f4d5f0bfb36fe"
       ],
       "layout": "IPY_MODEL_c674028a5a8845eb81cdbc1e36ede4aa"
      }
     },
     "5b9e9c00f7834a2a8ab4880a192468ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "63a41a99f89544619d1f4d5f0bfb36fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fc9da24cccff46418982243842cceafd",
       "placeholder": "",
       "style": "IPY_MODEL_a4397a083be442a5a2378f0c9effef48",
       "value": " 15219/? [05:26&lt;00:00, 46.65it/s]"
      }
     },
     "69c2e1f59da54797b3bedb32f9f3bfd7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "875c68685bb74e1ca7a2abb798e2a465": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_69c2e1f59da54797b3bedb32f9f3bfd7",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5b9e9c00f7834a2a8ab4880a192468ad",
       "value": 1.0
      }
     },
     "a4397a083be442a5a2378f0c9effef48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c674028a5a8845eb81cdbc1e36ede4aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc9da24cccff46418982243842cceafd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
